version: "3"

networks:
  default:
    name: hadoopnetwork

services:
  
  airflow-server:
    image: makengi12/airflow-server:1.0
    container_name: airflow-test-server
    hostname: airflow-server
    restart: always
    stdin_open: true
    depends_on:
      - airflow-db
    volumes:
        - airflow-volumes:/root/airflow
        - ../airflow_apps:/root/airflow_apps
        - ../airflow_dags:/root/airflow_dags
    ports:
      - 8087:8086
      - 2028:2028  
    tty: true
    environment:
      - HADOOP_HOME=/opt/hadoop
      - HADOOP_COMMON_HOME=/opt/hadoop
      - HADOOP_MAPRED_HOME=/opt/hadoop

  airflow-scheduler:
    image: makengi12/airflow-server:1.0
    container_name: airflow-scheduler
    hostname: airflow-scheduler
    restart: always
    volumes:
        - airflow-volumes:/root/airflow
    depends_on:
      - airflow-server
    environment:
      - SCHEDULER=True
      - HADOOP_HOME=/opt/hadoop
      - HADOOP_COMMON_HOME=/opt/hadoop
      - HADOOP_MAPRED_HOME=/opt/hadoop

  namenode:
    image: makengi12/namenode:1.0
    container_name: namenode
    hostname: namenode
    restart: always
    ports:
      - 9870:9870
      - 9000:9000
      - 27001:27001 # jmx
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
      - ./prometheus_agent:/agent
      - hadoop_conf:/opt
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_NAMENODE_OPTS=-javaagent:/agent/jmx_prometheus_javaagent-0.17.0.jar=27001:/agent/config.yaml $HDFS_NAMENODE_OPTS
    env_file:
      - ./hadoop.env

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    hostname: datanode
    restart: always
    depends_on:
      - namenode
    ports:
      - 9864:9864
      - 9866:9866
      - 27002:27002    
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
      - ./prometheus_agent:/agent
      - hadoop_conf:/opt
    environment:
      - SERVICE_PRECONDITION=namenode:9870
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_DATANODE_OPTS=-javaagent:/agent/jmx_prometheus_javaagent-0.17.0.jar=27002:/agent/config.yaml $HDFS_DATANODE_OPTS
    env_file:
      - ./hadoop.env


  resourcemanager:
    image: makengi12/resourcemanager:1.0
    container_name: resourcemanager
    hostname: resourcemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864"
    env_file:
      - ./hadoop.env
    ports:
      - "8088:8088"
      - "8032:8032"
      - "8031:8031"
      - "8030:8030"

  nodemanager1:
    image: makengi12/nodemanager:1.0
    container_name: nodemanager
    hostname: nodemanager
    restart: always
    ports:
      - 8042:8042
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    env_file:
      - ./hadoop.env

  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
    hostname: historyserver
    restart: always
    ports:
      - 8188:8188
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env

  # spark-master:
  #   image: makengi12/spark-master:1.3
  #   container_name: spark-master
  #   hostname: spark-master
  #   # build: ./master
  #   depends_on:
  #     - namenode
  #     - datanode
  #   ports:
  #     - "8085:8085"
  #     - "7077:7077"
  #   environment:
  #     - INIT_DAEMON_STEP=setup_spark
  #     - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
  #     - HADOOP_IP=192.168.0.12
  #   env_file:
  #     - ./hadoop.env  
      
  # spark-worker-1:
  #   image: makengi12/spark-worker:1.1
  #   container_name: spark-worker-1
  #   hostname: spark-worker-1
  #   depends_on:
  #     - spark-master
  #   ports:
  #     - "8081:8081"
  #   environment:
  #     - "SPARK_MASTER=spark://spark-master:7077"
  #     - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
  #     - MEMORY=4g
  #     - CORE=3
  #     - HADOOP_IP=192.168.0.12
  #   env_file:
  #     - ./hadoop.env  

  # spark-worker-2:
  #   image: makengi12/spark-worker:1.1
  #   container_name: spark-worker-2
  #   hostname: spark-worker-2
  #   depends_on:
  #     - spark-master
  #   ports:
  #     - "8082:8081"
  #   environment:
  #     - "SPARK_MASTER=spark://spark-master:7077"
  #     - MEMORY=4g
  #     - CORE=3
  #     - HADOOP_IP=192.168.0.12
  #   env_file:
  #     - ./hadoop.env    

  hive-server:
    image: makengi12/hive:3.1.2-postgresql-metastore
    container_name: hive-server
    hostname: hive-server
    depends_on:
      - namenode
      - datanode
    env_file:
      - ./hadoop-hive.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083"
      HADOOP_HOME: "/opt/hadoop-3.2.2"
      HADOOP_MAPRED_HOME: "/opt/hadoop-3.2.2"
    ports:
      - "10000:10000"
      - "10002:10002"

  hive-metastore:
    image: makengi12/hive:3.1.2-postgresql-metastore
    container_name: hive-metastore
    hostname: hive-metastore
    env_file:
      - ./hadoop-hive.env
    command: /opt/hive/bin/hive --service metastore --hiveconf hive.root.logger=DEBUG,console
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode:9864 hive-metastore-postgresql:5432"
      HADOOP_MAPRED_HOME: "/opt/hadoop-3.2.2"
      HADOOP_HOME: "/opt/hadoop-3.2.2"
    ports:
      - "9083:9083"

  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:3.1.0
    container_name: hive-metastore-postgresql
    ports:
      - "5433:5432"

  zeppelin:
    image: makengi12/zeppelin:1.0
    container_name: zeppelin
    # build: ./zeppelin
    ports:
      - "8080:8080"
    hostname: zeppelin  
    environment:
      ZEPPELIN_ADDR: '0.0.0.0'
      ZEPPELIN_NOTEBOOK_DIR: '/notebook'
      ZEPPELIN_LOG_DIR: '/logs'
      SPARK_HOME: '/spark'
    volumes:
       - zeppelin_logs:/logs
       - zeppelin_data:/data
       - zeppelin_notebook:/notebook
       - ../workspace/zeppelin_workspace:/root 

  grafana:
    image: grafana/grafana
    container_name: grafana
    ports:
      - "3000:3000"
    volumes:
       - grafana:/var/lib/grafana
       - grafana_conf:/usr/share/grafana/conf
       - ./test_apps:/test

  hbase-master:
    image: makengi12/hbase-master:1.0
    container_name: hbase-master
    # command: tail -f /dev/null
    hostname: hbase-master
    depends_on:
      - zookeeper1
      - zookeeper2
      - zookeeper3
    ports:
      - "16010:16010"  
    env_file:
      - ./hbase.env
    environment:
      SERVICE_PRECONDITION: "zookeeper1:2181 zookeeper2:2181 zookeeper3:2181"

  hbase-regionserver-1:
    image: makengi12/hbase-region:1.0
    hostname: hbase-regionserver-1
    container_name: hbase-regionserver-1
    ports:
      - "16020:16020"  
    depends_on:
      - hbase-master
      - zookeeper1
      - zookeeper2
      - zookeeper3
    env_file:
      - ./hbase.env
    environment:
      SERVICE_PRECONDITION: "hbase-master:16010 zookeeper1:2181 zookeeper2:2181 zookeeper3:2181"
      HBASE_CONF_hbase_regionserver_hostname: hbase-regionserver-1

  kafka_ui: 
    image: obsidiandynamics/kafdrop
    container_name: kafdrop 
    restart: "always"
    ports: 
      - "9020:9000"
    environment: 
      KAFKA_BROKERCONNECT: "kafka1:9092,kafka2:9092,kafka3:9092"
      JVM_OPTS: "-Xms32M -Xmx64M"

  flume:
    image: makengi12/flume:1.2
    container_name: flume
    restart: always
    ports:
      - 4545:4545 # Avro
    environment:
      configFile: OneM2M-Avro-Hdfs.conf
      agentName: OneM2M_Avro_Hdfs_Agent
    volumes:
      - ./flume_conf:/conf

  cloudera:
    image: gethue/hue:4.10.0
    hostname: hue
    container_name: hue
    restart: always
    dns: 8.8.8.8
    ports:
      - "8988:8988"
    volumes:
      - ./hue/ini/hue.ini:/usr/share/hue/desktop/conf/z-hue.ini
    depends_on:
      - "database"

  database:
    image: 'bitnami/mysql:latest'
    container_name: mysql
    restart: always
    ports:
      - "3306:3306"
    volumes:
      - data:/bitnami/mysql/data
    environment:
      - ALLOW_EMPTY_PASSWORD=yes 
      - MYSQL_USER=hue
      - MYSQL_PASSWORD=hue
      - MYSQL_DATABASE=hue

  presto-master:
    image: 'makengi12/prestodb:1.0'
    container_name: presto-master
    hostname: presto-master
    environment:
      - WORKER=false
    restart: always
    ports:
      - "8079:8080"

  presto-worker:
    image: 'makengi12/prestodb-worker:1.0'
    container_name: presto-worker
    hostname: presto-worker
    restart: always
    environment:
      - WORKER_ID=worker1

  airflow-db:
    image: 'makengi12/airflow-db:1.0'         
    container_name: airflow-db
    ports:
      - "3310:3306"
    restart: always
    volumes:
      - airflow-db:/var/lib/mysql
      - airflow-db-conf:/etc/mysql
    environment:
      - MYSQL_ROOT_PASSWORD=1212
      - MYSQL_DATABASE=airflow

  test-db:
    image: 'makengi12/airflow-db:1.0'         
    container_name: test-db
    ports:
      - "3309:3306"
    restart: always
    volumes:
      - test-db:/var/lib/mysql
      - test-db-conf:/etc/mysql
    environment:
      - MYSQL_ROOT_PASSWORD=1212
      - MYSQL_DATABASE=test_db

  influxdb:
    image: bitnami/influxdb:latest
    container_name: influxdb
    ports:
      - 8086:8086
      - 8085:8088
    environment:
      - INFLUXDB_ADMIN_USER_PASSWORD=bitnami123
      - INFLUXDB_ADMIN_USER_TOKEN=admintoken123
      - INFLUXDB_USER=root
      - INFLUXDB_USER_PASSWORD=bitnami123
      - INFLUXDB_HTTP_AUTH_ENABLED=false
      - INFLUXDB_DB=my_database
    volumes:
      - influxdb_data:/bitnami/influxdb
 
  zookeeper1:
    image: 'bitnami/zookeeper:3.7'
    container_name: zookeeper1
    ports:
      - '2181:2181'
    volumes:
      - zookeeper1:/bitnami/zookeeper
    environment:
      - ZOO_SERVER_ID=1
      - ZOO_SERVERS=0.0.0.0:2888:3888,zookeeper2:2888:3888,zookeeper3:2888:3888
      - ALLOW_ANONYMOUS_LOGIN=yes

  zookeeper2:
    image: 'bitnami/zookeeper:3.7'
    container_name: zookeeper2
    ports:
      - '2182:2181'
    volumes:
      - zookeeper2:/bitnami/zookeeper
    environment:
      - ZOO_SERVER_ID=2
      - ZOO_SERVERS=zookeeper1:2888:3888,0.0.0.0:2888:3888,zookeeper3:2888:3888
      - ALLOW_ANONYMOUS_LOGIN=yes

  zookeeper3:
    image: 'bitnami/zookeeper:3.7'
    container_name: zookeeper3
    ports:
      - '2183:2181'
    volumes:
      - zookeeper3:/bitnami/zookeeper
    environment:
      - ZOO_SERVER_ID=3
      - ZOO_SERVERS=zookeeper1:2888:3888,zookeeper2:2888:3888,0.0.0.0:2888:3888                
      - ALLOW_ANONYMOUS_LOGIN=yes

  kafka1:
    image: 'bitnami/kafka:3.1.0'
    container_name: kafka1
    hostname: kafka1
    ports:
      - '9093:9093'
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper1:2181,zookeeper2:2181,zookeeper3:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CLIENT:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_LISTENERS=CLIENT://:9092,EXTERNAL://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=CLIENT://kafka1:9092,EXTERNAL://192.168.0.12:9093
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=CLIENT
    volumes:
      - kafka1:/bitnami/kafka  

  kafka2:
    image: 'bitnami/kafka:3.1.0'
    container_name: kafka2
    hostname: kafka2
    ports:
      - '9094:9094'
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper1:2181,zookeeper2:2181,zookeeper3:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CLIENT:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_LISTENERS=CLIENT://:9092,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=CLIENT://kafka2:9092,EXTERNAL://192.168.0.12:9094
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=CLIENT
      # - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092
    volumes:
      - kafka2:/bitnami/kafka    

  kafka3:
    image: 'bitnami/kafka:3.1.0'
    container_name: kafka3
    hostname: kafka3
    ports:
      - '9095:9095'
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper1:2181,zookeeper2:2181,zookeeper3:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CLIENT:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_LISTENERS=CLIENT://:9092,EXTERNAL://:9095
      - KAFKA_CFG_ADVERTISED_LISTENERS=CLIENT://kafka3:9092,EXTERNAL://192.168.0.12:9095
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=CLIENT
      # - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092
    volumes:
      - kafka3:/bitnami/kafka

  nimbus:
    image: storm:latest
    container_name: nimbus
    command: storm nimbus
    depends_on:
      - zookeeper1
      - zookeeper2
      - zookeeper3
    restart: always
    ports:
      - 6627:6627
    volumes:
       - storm:/conf/

  supervisor-ui:
    image: storm:latest
    container_name: supervisor-ui
    command: storm ui
    depends_on:
        - nimbus
    ports:
     - "6060:8080"
    volumes:
       - storm:/conf/

  supervisor:
    image: storm:latest
    container_name: supervisor
    command: storm supervisor
    depends_on:
      - zookeeper1
      - zookeeper2
      - zookeeper3
      - nimbus
    restart: always
    volumes:
       - storm:/conf/

  prometheus:
    image: docker.io/bitnami/prometheus:2
    ports:
      - '9190:9090'
    volumes:
      - prometheus:/opt/bitnami/prometheus  

  jmx-exporter:
    image: docker.io/bitnami/jmx-exporter:0.17.0-debian-11-r4
    ports:
      - 5556:5556                   

  nifi:
    image: apache/nifi:1.13.2
    container_name: nifi
    ports:
      - '7070:8080'
    volumes:
       - hadoop_conf:/hadoop_conf  
    environment:
      - NIFI_WEB_HTTP_PORT=8080
      - NIFI_CLUSTER_IS_NODE=true
      - NIFI_CLUSTER_NODE_PROTOCOL_PORT=8082
      - NIFI_ZK_CONNECT_STRING=zookeeper1:2181,zookeeper2:2181,zookeeper3:2181
      - NIFI_ZK_ROOT_NODE=/nifi
      - NIFI_ELECTION_MAX_WAIT=1 min
      

volumes:
  hadoop_namenode:
  hadoop_conf:
  hadoop_datanode:
  prometheus:
  hadoop_historyserver:
  zeppelin_logs:
  zeppelin_data:
  zeppelin_notebook:
  grafana:
  grafana_conf:
  zookeeper1:
  zookeeper2:
  zookeeper3:
  kafka1:
  kafka2:
  kafka3:
  storm:
  data:
  flume_conf:
  airflow-volumes:
  airflow-db:
  airflow-db-conf:
  test-db:
  test-db-conf: 
  influxdb_data:
